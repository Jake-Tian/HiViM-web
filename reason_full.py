import json
import pickle
from pathlib import Path
from reason import reason
from utils.graph_reasoning import reason_from_graph


def evaluate_answer(question, ground_truth_answer, predicted_answer):
    """
    Evaluate if the predicted answer is correct using GPT-4o-mini.
    
    Args:
        question: The question being answered
        ground_truth_answer: The correct answer
        predicted_answer: The answer generated by the system
    
    Returns:
        bool: True if the answer is correct, False otherwise
    """
    # Compare first capital letter (A-D) only
    if ground_truth_answer is None or predicted_answer is None:
        return False
    gt = str(ground_truth_answer).strip().upper()
    pred = str(predicted_answer).strip().upper()
    if not gt or not pred:
        return False
    return gt[0] == pred[0]


def find_pkl_files(semantic_memory_dir="data/semantic_memory"):
    """
    Find all .pkl files in the semantic memory directory and extract video names.
    
    Args:
        semantic_memory_dir: Directory containing .pkl graph files
    
    Returns:
        set: Set of video names (without .pkl extension)
    """
    semantic_path = Path(semantic_memory_dir)
    if not semantic_path.exists():
        raise FileNotFoundError(f"Semantic memory directory not found: {semantic_memory_dir}")
    
    pkl_files = list(semantic_path.glob("*.pkl"))
    video_names = {f.stem for f in pkl_files}
    
    return video_names


def load_questions(json_path="data/questions.jsonl"):
    """
    Load questions from questions.jsonl file.

    Args:
        json_path: Path to the questions.jsonl file
    
    Returns:
        list: List of question dicts
    """
    json_file = Path(json_path)
    if not json_file.exists():
        raise FileNotFoundError(f"Questions file not found: {json_path}")

    questions = []
    if json_file.suffix == ".jsonl":
        with open(json_file, 'r', encoding='utf-8') as f:
            for idx, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                try:
                    item = json.loads(line)
                except json.JSONDecodeError:
                    continue
                item["_line_number"] = idx
                questions.append(item)
    else:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        # If it's a list of questions, use it directly
        if isinstance(data, list):
            questions = data
        else:
            # Fallback: attempt to flatten dict format
            for _, qa_list in data.items():
                if isinstance(qa_list, list):
                    questions.extend(qa_list)

    return questions


def process_all_videos(output_dir="data/results", output_filename="results.json"):
    """
    Process all videos and answer all questions.
    
    Args:
        output_dir: Directory to save results
        output_filename: Name of the output JSON file
    
    Returns:
        dict: Dictionary with question_id as keys and results as values
    """
    # Find all videos with .pkl files
    print("Finding available videos...")
    available_videos = find_pkl_files()
    print(f"Found {len(available_videos)} videos: {sorted(available_videos)}")
    
    # Load questions
    print("\nLoading questions...")
    questions_data = load_questions()
    
    # Filter questions for available videos
    all_questions = []
    for qa in questions_data:
        video_name = qa.get("video_id") or qa.get("video_name")
        if not video_name or video_name not in available_videos:
            continue
        qa["video_name"] = video_name
        all_questions.append(qa)

    print(f"Found {len(all_questions)} questions across {len({q['video_name'] for q in all_questions})} videos")
    
    # Process each question
    results = {}
    semantic_memory_dir = Path("data/semantic_memory")
    
    for i, qa in enumerate(all_questions, 1):
        question_id = qa.get("question_id")
        if not question_id:
            line_no = qa.get("_line_number", i)
            question_id = f"{qa.get('video_name', 'video')}_{line_no}"
        question_text = qa.get("question_text") or qa.get("question") or ""
        options = qa.get("options") or {}
        if isinstance(options, dict) and options:
            options_text = "\n".join([f"{k}: {v}" for k, v in options.items()])
            question = f"{question_text}\nOptions:\n{options_text}"
        else:
            question = question_text
        video_name = qa["video_name"]
        ground_truth = qa.get("correct_answer") or qa.get("answer")
        reasoning = qa.get("explanation", "") or qa.get("reasoning", "")
        timestamp = qa.get("segment_info", {}).get("timestamp", "") or qa.get("timestamp", "")
        qa_type = qa.get("category", "") or qa.get("type", [])
        before_clip = qa.get("before_clip", None)
        
        print(f"\nProcessing question {i}/{len(all_questions)}: {question_id}")
        print(f"Video: {video_name}")
        
        try:
            # Load graph for this video
            graph_path = semantic_memory_dir / f"{video_name}.pkl"
            if not graph_path.exists():
                print(f"Warning: Graph file not found for {video_name}. Skipping.")
                continue
            
            with open(graph_path, "rb") as f:
                graph = pickle.load(f)
            
            # Run reasoning
            reason_result = reason(question, graph, video_name)
            # reason_result = reason_from_graph(question, graph)
            
            # Evaluate answer
            predicted_answer = reason_result.get("final_answer", reason_result.get("answer", ""))
            is_correct = evaluate_answer(question, ground_truth, predicted_answer)
            
            # Add evaluation result and qa_list information to reason_result
            reason_result["evaluator_correct"] = is_correct
            reason_result["ground_truth_answer"] = ground_truth
            reason_result["reasoning"] = reasoning
            reason_result["timestamp"] = timestamp
            reason_result["type"] = qa_type
            reason_result["before_clip"] = before_clip
            
            # Store result
            results[question_id] = reason_result
            
            print(f"\nGround Truth: {ground_truth}")
            print(f"Predicted: {predicted_answer}")
            print(f"Evaluator Result: {is_correct}")
            
        except Exception as e:
            print(f"Error processing question {question_id}: {e}")
            import traceback
            traceback.print_exc()
            # Store error result
            results[question_id] = {
                "error": str(e),
                "video_name": video_name,
                "question": question,
                "ground_truth_answer": ground_truth,
                "reasoning": reasoning,
                "timestamp": timestamp,
                "type": qa_type,
                "before_clip": before_clip,
                "evaluator_correct": False
            }
    
    # Save results
    output_path = Path(output_dir) / output_filename
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Load existing results if file exists
    existing_results = {}
    if output_path.exists():
        print(f"Loading existing results from {output_path}")
        try:
            with open(output_path, 'r', encoding='utf-8') as f:
                existing_results = json.load(f)
            print(f"Loaded {len(existing_results)} existing results")
        except Exception as e:
            print(f"Warning: Could not load existing results: {e}. Starting fresh.")
            existing_results = {}
    
    # Merge new results into existing results (overwrite if question_id already exists)
    existing_results.update(results)
    
    print(f"Saving results to {output_path}")
    print(f"Total results: {len(existing_results)} (including {len(results)} new/updated)")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(existing_results, f, indent=2, ensure_ascii=False)
    
    # Print summary (based on merged results)
    total = len(existing_results)
    correct = sum(1 for r in existing_results.values() if r.get("evaluator_correct", False))
    errors = sum(1 for r in existing_results.values() if "error" in r)
    
    print(f"\nSummary:")
    print(f"Total questions: {total}")
    print(f"Correct answers: {correct}")
    print(f"Accuracy: {correct/total*100:.2f}%" if total > 0 else "N/A")
    print(f"Errors: {errors}")
    
    return existing_results


if __name__ == "__main__":
    import sys
    
    output_filename = sys.argv[1] if len(sys.argv) > 1 else "results.json"
    
    try:
        results = process_all_videos(output_filename=output_filename)
    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
