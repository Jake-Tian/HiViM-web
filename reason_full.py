import json
import pickle
from pathlib import Path
from reason import reason
from utils.graph_reasoning import reason_from_graph
from utils.llm import generate_text_response
from utils.prompts import prompt_agent_verify_answer_referencing


def evaluate_answer(question, ground_truth_answer, predicted_answer):
    """
    Evaluate if the predicted answer is correct using GPT-4o-mini.
    
    Args:
        question: The question being answered
        ground_truth_answer: The correct answer
        predicted_answer: The answer generated by the system
    
    Returns:
        bool: True if the answer is correct, False otherwise
    """
    prompt = prompt_agent_verify_answer_referencing.format(
        question=question,
        ground_truth_answer=ground_truth_answer,
        agent_answer=predicted_answer
    )
    
    try:
        response = generate_text_response(prompt)
        # Clean the response - extract Yes/No
        response = response.strip().upper()
        if response.startswith("YES"):
            return True
        elif response.startswith("NO"):
            return False
        else:
            # If response is ambiguous, default to False
            print(f"Warning: Unexpected evaluator response: {response}. Defaulting to False.")
            return False
    except Exception as e:
        print(f"Error evaluating answer: {e}. Defaulting to False.")
        return False


def find_pkl_files(semantic_memory_dir="data/semantic_memory"):
    """
    Find all .pkl files in the semantic memory directory and extract video names.
    
    Args:
        semantic_memory_dir: Directory containing .pkl graph files
    
    Returns:
        set: Set of video names (without .pkl extension)
    """
    semantic_path = Path(semantic_memory_dir)
    if not semantic_path.exists():
        raise FileNotFoundError(f"Semantic memory directory not found: {semantic_memory_dir}")
    
    pkl_files = list(semantic_path.glob("*.pkl"))
    video_names = {f.stem for f in pkl_files}
    
    return video_names


def load_questions(json_path="data/web.json"):
    """
    Load questions from web.json file.

    Args:
        json_path: Path to the web.json file
    
    Returns:
        dict: Dictionary with video names as keys and question lists as values
    """
    json_file = Path(json_path)
    if not json_file.exists():
        raise FileNotFoundError(f"Questions file not found: {json_path}")
    
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    return data


def process_all_videos(output_dir="data/results", output_filename="results.json"):
    """
    Process all videos and answer all questions.
    
    Args:
        output_dir: Directory to save results
        output_filename: Name of the output JSON file
    
    Returns:
        dict: Dictionary with question_id as keys and results as values
    """
    # Find all videos with .pkl files
    print("Finding available videos...")
    available_videos = find_pkl_files()
    print(f"Found {len(available_videos)} videos: {sorted(available_videos)}")
    
    # Load questions
    print("\nLoading questions...")
    questions_data = load_questions()
    
    # Filter questions for available videos
    all_questions = []
    for video_name, video_data in questions_data.items():
        if video_name in available_videos:
            qa_list = video_data.get("qa_list", [])
            for qa in qa_list:
                qa["video_name"] = video_name
                all_questions.append(qa)
    
    print(f"Found {len(all_questions)} questions across {len([v for v in questions_data.keys() if v in available_videos])} videos")
    
    # Process each question
    results = {}
    semantic_memory_dir = Path("data/semantic_memory")
    
    for i, qa in enumerate(all_questions, 1):
        question_id = qa["question_id"]
        question = qa["question"]
        video_name = qa["video_name"]
        ground_truth = qa["answer"]
        reasoning = qa.get("reasoning", "")
        timestamp = qa.get("timestamp", "")
        qa_type = qa.get("type", [])
        before_clip = qa.get("before_clip", None)
        
        print(f"\nProcessing question {i}/{len(all_questions)}: {question_id}")
        print(f"Video: {video_name}")
        
        try:
            # Load graph for this video
            graph_path = semantic_memory_dir / f"{video_name}.pkl"
            if not graph_path.exists():
                print(f"Warning: Graph file not found for {video_name}. Skipping.")
                continue
            
            with open(graph_path, "rb") as f:
                graph = pickle.load(f)
            
            # Run reasoning
            reason_result = reason(question, graph, video_name)
            # reason_result = reason_from_graph(question, graph)
            
            # Evaluate answer
            predicted_answer = reason_result.get("final_answer", reason_result.get("answer", ""))
            is_correct = evaluate_answer(question, ground_truth, predicted_answer)
            
            # Add evaluation result and qa_list information to reason_result
            reason_result["evaluator_correct"] = is_correct
            reason_result["ground_truth_answer"] = ground_truth
            reason_result["reasoning"] = reasoning
            reason_result["timestamp"] = timestamp
            reason_result["type"] = qa_type
            reason_result["before_clip"] = before_clip
            
            # Store result
            results[question_id] = reason_result
            
            print(f"\nGround Truth: {ground_truth}")
            print(f"Predicted: {predicted_answer}")
            print(f"Evaluator Result: {is_correct}")
            
        except Exception as e:
            print(f"Error processing question {question_id}: {e}")
            import traceback
            traceback.print_exc()
            # Store error result
            results[question_id] = {
                "error": str(e),
                "video_name": video_name,
                "question": question,
                "ground_truth_answer": ground_truth,
                "reasoning": reasoning,
                "timestamp": timestamp,
                "type": qa_type,
                "before_clip": before_clip,
                "evaluator_correct": False
            }
    
    # Save results
    output_path = Path(output_dir) / output_filename
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Load existing results if file exists
    existing_results = {}
    if output_path.exists():
        print(f"Loading existing results from {output_path}")
        try:
            with open(output_path, 'r', encoding='utf-8') as f:
                existing_results = json.load(f)
            print(f"Loaded {len(existing_results)} existing results")
        except Exception as e:
            print(f"Warning: Could not load existing results: {e}. Starting fresh.")
            existing_results = {}
    
    # Merge new results into existing results (overwrite if question_id already exists)
    existing_results.update(results)
    
    print(f"Saving results to {output_path}")
    print(f"Total results: {len(existing_results)} (including {len(results)} new/updated)")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(existing_results, f, indent=2, ensure_ascii=False)
    
    # Print summary (based on merged results)
    total = len(existing_results)
    correct = sum(1 for r in existing_results.values() if r.get("evaluator_correct", False))
    errors = sum(1 for r in existing_results.values() if "error" in r)
    
    print(f"\nSummary:")
    print(f"Total questions: {total}")
    print(f"Correct answers: {correct}")
    print(f"Accuracy: {correct/total*100:.2f}%" if total > 0 else "N/A")
    print(f"Errors: {errors}")
    
    return existing_results


if __name__ == "__main__":
    import sys
    
    output_filename = sys.argv[1] if len(sys.argv) > 1 else "results.json"
    
    try:
        results = process_all_videos(output_filename=output_filename)
    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
